{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc6f32d-544f-4f24-9e75-733a6bb084f5",
   "metadata": {},
   "source": [
    "# Analysing Other Models\n",
    "### Author: Ben Newell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d02a6f32-f332-4e87-9455-f4dfd346c48f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9aa1faa-15d1-4c37-be3b-7656e3f72b3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(r\"C:\\Users\\benne\\OneDrive\\Desktop\\Important things\\data science\\Group project\\datasets\\bird_final.csv\")\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2ed5f-ad70-401b-97e9-55ec5c8c9d27",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e158772-f289-463d-bd16-30d233937a68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947878d4-ea58-48e0-ab1e-b6dfa42104e3",
   "metadata": {},
   "source": [
    "### Linear Regression, Random Forrest, SVR and Gradient Boosting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801412f-45a6-4e4b-abfa-abea1f955263",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Additional feature engineering\n",
    "df_clean['ELEVATION'] = df_clean['LATITUDE'].abs() + df_clean['LONGITUDE'].abs()\n",
    "df_clean['TEMP_RAIN_INTERACTION'] = df_clean['AVERAGE MONTH TEMPERATURE'] * df_clean['AVERAGE MONTH RAINFALL']\n",
    "df_clean['POPULATION_DENSITY_LOG'] = np.log1p(df_clean['Population Density'])\n",
    "df_clean['AREA_FACTOR'] = df_clean['LATITUDE'].abs() * df_clean['LONGITUDE'].abs()\n",
    "df_clean['SEASON'] = pd.cut(df_clean['month'], \n",
    "                           bins=[0, 3, 6, 9, 12], \n",
    "                           labels=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "df_clean = pd.get_dummies(df_clean, columns=['SEASON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ca257-8c84-4ea3-bb4b-6d513d2e29b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302c710-f619-49c5-bd11-9967c87d654e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Updated features list\n",
    "features = ['LATITUDE', 'LONGITUDE', 'AVERAGE MONTH TEMPERATURE', \n",
    "           'AVERAGE MONTH RAINFALL', 'tree_loss_ha', 'percentage_loss',\n",
    "           'Population', 'NDVI', 'Population Density', 'month', 'WT_COUNT_10KM_RADIUS',\n",
    "           'TEMP_RAIN_INTERACTION', 'POPULATION_DENSITY_LOG', 'AREA_FACTOR',\n",
    "           'ELEVATION', 'SEASON_Winter', 'SEASON_Spring', 'SEASON_Summer', 'SEASON_Fall']\n",
    "\n",
    "# Prepare data\n",
    "X = df_clean[features]\n",
    "y = df_clean['OBSERVATION COUNT']\n",
    "\n",
    "# Split and scale data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Updated models with better parameters\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'SVR': SVR(\n",
    "        kernel='rbf',\n",
    "        C=100,\n",
    "        gamma='scale'\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train models and store results\n",
    "predictions = {}\n",
    "importance_models = {}\n",
    "metrics = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train and predict\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    pred = model.predict(X_test_scaled)\n",
    "    predictions[name] = pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    metrics[name] = {'MSE': mse, 'R2': r2}\n",
    "    \n",
    "    # Store feature importance if available\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance_models[name] = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, (name, pred) in enumerate(predictions.items(), 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(y_test, pred, alpha=0.5, s=20)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{name}\\nMSE: {metrics[name][\"MSE\"]:.2f}, R2: {metrics[name][\"R2\"]:.2f}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot feature importance for models that support it\n",
    "for name, importance in importance_models.items():\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Only show top 15 features for clarity\n",
    "    top_features = importance.head(15)\n",
    "    sns.barplot(x='importance', y='feature', data=top_features)\n",
    "    plt.title(f'Top 15 Features Importance - {name}')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Print detailed metrics\n",
    "print(\"\\nDetailed Model Performance:\")\n",
    "for name, metric in metrics.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Mean Squared Error: {metric['MSE']:.2f}\")\n",
    "    print(f\"R-squared Score: {metric['R2']:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(metric['MSE']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
